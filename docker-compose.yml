services:
  kafka-cluster:
    image: apache/kafka:${KAFKA_VERSION:-4.1.0}
    platform: linux/amd64
    hostname: kafka-cluster
    container_name: kafka-cluster
    ports:
      - "9092:9092"
      - "9101:9101" # JMX.
    environment:
      # KRaft.
      KAFKA_PROCESS_ROLES: broker, controller
      KAFKA_BROKER_ID: 1
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-cluster:29093

      # Listeners.
      KAFKA_LISTENERS: INTERNAL://kafka-cluster:29092, CONTROLLER://kafka-cluster:29093, EXTERNAL://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-cluster:29092, EXTERNAL://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT, EXTERNAL:PLAINTEXT, CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      # Metrics.
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost

      # Other.
      KAFKA_LOG_DIRS: /tmp/logs
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 3

  # ----- Flink cluster ----- #

  # Job manager separate container in session mode.
  job-manager:
    build:
      context: .
      args:
        - FLINK_VERSION=${FLINK_VERSION}
        - FLINK_KAFKA_SQL_CONNECTOR_VERSION=${FLINK_KAFKA_SQL_CONNECTOR_VERSION}
        - FLINK_FAKER_VERSION=${FLINK_FAKER_VERSION}
    hostname: job-manager
    container_name: job-manager
    command: jobmanager
    ports:
      - "8081:8081"
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: job-manager
        state.backend: hashmap
        state.checkpoints.dir: file:///tmp/flink-checkpoints
        heartbeat.interval: 1000
        heartbeat.timeout: 5000
        rest.flamegraph.enabled: true
        web.backpressure.refresh-interval: 10000
    volumes:
      - flink_data:/tmp/

  # Spawns a single task manager in its own container.
  task-manager:
    build:
      context: .
      args:
        - FLINK_VERSION=${FLINK_VERSION}
        - FLINK_KAFKA_SQL_CONNECTOR_VERSION=${FLINK_KAFKA_SQL_CONNECTOR_VERSION}
        - FLINK_FAKER_VERSION=${FLINK_FAKER_VERSION}
    depends_on:
      - job-manager
    hostname: task-manager
    container_name: task-manager
    command: taskmanager
    scale: 1
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: job-manager
        taskmanager.numberOfTaskSlots: 3
        state.backend: hashmap
        state.checkpoints.dir: file:///tmp/flink-checkpoints
        heartbeat.interval: 1000
        heartbeat.timeout: 5000
    volumes:
      - flink_data:/tmp/

  # Flink SQL client.
  sql-client:
    build:
      context: .
      args:
        - FLINK_VERSION=${FLINK_VERSION}
        - FLINK_KAFKA_SQL_CONNECTOR_VERSION=${FLINK_KAFKA_SQL_CONNECTOR_VERSION}
        - FLINK_FAKER_VERSION=${FLINK_FAKER_VERSION}
    depends_on:
      - job-manager
    hostname: sql-client
    container_name: sql-client
    command: bin/sql-client.sh
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: job-manager
        rest.address: job-manager   

# Defines a custom volume for Flink containers to share checkpoint data and logs.
volumes:
  flink_data: